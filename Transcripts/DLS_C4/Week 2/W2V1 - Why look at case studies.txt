Hello. Welcome back. This week, the first thing we'll do
is show you a number of case studies of effective
convolutional neural networks. Why look at case studies? Last week we learned about
the basic building blocks, such as convolutional
layers, pooling layers, and fully connected
layers of convnet. It turns out the past few years of computer vision research
has been on how to put together these basic
building blocks to form effective convolutional
neural networks. One of the best ways
for user gain intuition yourself is to see some
of these examples. I think just as many of
you may have learned to write code by reading
other people's codes, I think that a good way to gain intuition and how the
build confidence is to read or to see other examples
of effective confidence. It turns out that a neural network
architecture that works well on one computer
vision tasks often works well on
other tasks as well, such as maybe on your task. If someone else's train a neural network or has figured out a neural
network architecture, there's very good at recognizing cats and dogs and people. But you have a different
computer vision tasks like maybe you're trying to
build a self-driving car, you might well be able to take someone else's neural
network architecture and apply that to your problem. Finally, after the
next few videos, you'll be able to read some of the research papers from the
field of computer vision, and I hope that you might
find it satisfying as well. You don't have to
do this as class where you might
find it satisfying, typically read some of these several computer
vision research paper and see yourself able
to understand them. With that, let's get started. As an outline for what we'll
do in the next few videos, we'll first show you a
few classic networks. LeNet-5 network which
came from, I guess, in 1980s, AlexNet which is often cited in
the VGG network. These are examples of pretty
effective neural networks, and you see ideas from
these papers that will probably be useful for
your own work as well. Then I want to show you the ResNet or called
residual network. You might have heard
that neural networks and getting deeper and deeper, the ResNet neural
network trained a very deep 152 layer
neural network. It has some very
interesting tricks, interesting ideas how
they do that effectively. Then finally, you also see a case study of the
Inception neural network. After seeing these
neural networks, I think you have much
better intuition about how to build effective convolutional
neural networks. Even if you end up not working
computer vision yourself, you find a lot of the ideas
from some of these examples, such as ResNet,
Inception network, many of these ideas
are cross fertilizing, are making their way
into other disciplines. Even if you don't
end up building computer vision
applications yourself, I think you'll find
some of these ideas very interesting and
helpful for your work.