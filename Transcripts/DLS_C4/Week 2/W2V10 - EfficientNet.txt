MobileNet V1 and V2 gave you a way to implement
a neural network, that is more
computationally efficient. But is there a way
to tune MobileNet, or some other architecture, to your specific device? Maybe you're implementing a
computer vision algorithm for different brands of
mobile phones with different amounts of
compute resources, or for different edge devices. If you have a little
bit more computation, maybe you have a slightly
bigger neural network and hopefully you get
a bit more accuracy, or if you are more
computationally constraint, maybe you want a slightly
smaller neural network that runs a bit faster, at the cost of a little
bit of accuracy. How can you automatically
scale up or down neural networks for
a particular device? EfficientNet, gives
you a way to do so. Let's say you have a baseline neural
network architecture, where the input image has
a certain resolution r, and your new network
has a certain depth, and the layers has
a certain width. The authors of the
EfficientNet paper, Mingxing Tan and my former
PhD student, Quoc Le, observed that the
three things you could do to scale
things up or down, are, you could use a
high resolution image. So a new image resolution r. I don't know how to denote a high resolution
in a video like this. I'm using this blue
glow here to denote, maybe high resolution image. Or you could make this
network much deeper. You could vary d to depth
of the neural network, or you can make the layers wider. You can also vary the
width of these layers. The question is, given a
particular computational budget, what's the good choice
of r, d, and w? Or depending on the computational
resources you have, you can also use
compound scaling, where you might
simultaneously scale up or simultaneously scale down
the resolution of the image, and the depth, and the width
of the neural network. Now the tricky part is, if you want to scale up r, d, and w, what's the rate at which you should scale
up each of these? Should you double the resolution and leave depth with the same, or maybe you should
double the depth, but leave the others the same, or increase resolution
by 10 percent, increase depth by 50 percent, and width by 20 percent? What's the best trade-off
between r, d, and w, to scale up or down
your neural network, to get the best
possible performance within your computational budget? If you are ever looking to adapt a neural network architecture
for a particular device, look at one of the open source implementations
of EfficientNet, which will help you to choose
a good trade-off between r, d, and w. That's it. With MobileNet, you've
learned how to build more computationally efficient
layers, and with EfficientNet, you can also find a way
to scale up or down these neural networks based on the resources of a device
you may be working on. With this, I hope
you have the skills needed in order to build
neural networks for mobile devices and for
embedded devices and for other devices where
the computation in a memory maybe more limited. I hope this will open up a lot of possible applications that
you may now be able to build.